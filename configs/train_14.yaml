seed: 42
steps: 160000
warmup_steps: 2000
batch_size: 128
test_batch_size: 32
nhead: 8
d_model: 1024
num_encoder_layers: 16
num_decoder_layers: 16
use_pe: True
use_ls: True
norm_first: False
vocab_size: [5000,5000]
dropout: 0.3
lr: 5e-4
betas: [0.9,0.98]
warmup_init_lr: 1e-7
warmup_end_lr: 5e-4
pad_idx: 3
dataset_type: seperate  # 'combined', 'seperate', 'origin'
device: cuda:0
optimizer: Adam

train_path: ./dataset/seperate_bpe_preprocess/training.txt
test_path: ./dataset/seperate_bpe_preprocess/testing.txt
val_path: ./dataset/seperate_bpe_preprocess/validation.txt

cn_model_path: ./dataset/seperate_bpe_preprocess/cn_bpe.model
en_model_path: ./dataset/seperate_bpe_preprocess/en_bpe.model

output_path: ./results/result_14

log_interval: 100
val_interval: 500
test_interval: 500
accumulate_interval: 8