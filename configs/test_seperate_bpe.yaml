model_path: ./results/result_10/vanilla_transformer.pth
word2int_en: ./dataset/seperate_bpe_preprocess/token2int_en.json
int2word_cn: ./dataset/seperate_bpe_preprocess/int2token_cn.json

bos_idx: 1
eos_idx: 2
pad_idx: 3
max_len: 70
device: cuda

vocab_size: [5000,5000]
nhead: 8
d_model: 1024
num_encoder_layers: 6
num_decoder_layers: 6
dropout: 0.1
use_pe: True
norm_first: False