model_path: ./results/result_18/vanilla_transformer.pth
word2int_en: ./dataset/combine_BPE_preprocess/token2int.json
int2word_cn: ./dataset/combine_BPE_preprocess/int2token.json

bos_idx: 1
eos_idx: 2
pad_idx: 3
max_len: 70
device: cuda

vocab_size: [8000,8000]
nhead: 8
d_model: 1024
num_encoder_layers: 6
num_decoder_layers: 6
dropout: 0.1
use_pe: True
norm_first: False